---
title: Asymptotic Complexity
date: 05-10-2003
slides: 
---

## How long does code take to run?

Here is a program written in C.
```c
for(int i = 0; i < N; i++)
    for(int j = 0; i < N; j++)
        printf("Hello again, world!")
```

What method should we use to answer this question?

We *could*  just time it, but...
* This is inconsistent between machines,
* It isn't general for all inputs.

A batter approach might be to analyze the code, without running it.
This practice is called ***static analysis*** of code &mdash; this technique is used by many compilers, linters, IDEs, etc.


## Big-$O$ Notation
### Definition
Given a function $g(n)$, we say that "$f(n)$ is $O\left(g(n)\right)$" if there exists $c > 0$ and a $n_0 \geq 0$such that for any $n \geq n_0$:
$$0 \leq f(n) \leq cg(n)$$

For example: $3n^2 + 4n + 1$ is $O(n^2)$ as you can find a valid $c$: $c = 4$.

### Big-$\Omega$
This is like the opposite of Big-$O$ notation, where it is defined as:
> Given a function $g(n)$, we say that "$f(n)$ is $O\left(g(n)\right)$" if there exists $c > 0$ and a $n_0 \geq 0$such that for any $n \geq n_0$:
> $$0 \leq cg(n) \leq f(n)$$

Big-$\Omega$ is the lower asymptotic bound.
