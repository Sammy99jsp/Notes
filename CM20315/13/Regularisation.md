---
slides: https://moodle.bath.ac.uk/mod/resource/view.php?id=1277634
---
How do we make our models more general, or *regular* -- currently, our models can be a victim of over-fitting, where it perfectly can describe the training data, but is not good for unseen data.


Essentially, regularisation is finagling the loss function by adding extra things to consider.

[[Explicit Regularisation]]
[[L2 Regularisation]]
[[Implicit Regularisation]]
[[Early Stopping]]
[[Ensembling]]